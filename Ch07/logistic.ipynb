{"cells":[{"cell_type":"code","execution_count":null,"id":"1a456ff7-140b-4304-abcd-f448eff4dcb6","metadata":{},"outputs":[],"source":["# Static variables\n","BUCKET='elite-caster-125113'"]},{"cell_type":"code","execution_count":null,"id":"00d224a1-74af-4587-84b1-2bafd96d5519","metadata":{},"outputs":[],"source":["# Init spark session\n","from pyspark.sql import SparkSession\n","from pyspark.sql.dataframe import DataFrame\n","spark = SparkSession\\\n","  .builder \\\n","  .appName(\"Logistic regression w/ Spark ML\") \\\n","  .getOrCreate()"]},{"cell_type":"code","execution_count":null,"id":"bd6f1673-ab02-447e-aca1-27700c82527e","metadata":{},"outputs":[],"source":["# Import modules \n","from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n","from pyspark.mllib.regression import LabeledPoint\n","from pyspark.rdd import PipelinedRDD\n","import numpy as np\n","from collections import namedtuple\n","from matplotlib import pyplot as plt\n","from google.cloud import storage\n","from typing import Tuple"]},{"cell_type":"markdown","id":"f86ebc78-9a2f-464a-91d1-f4d92395448d","metadata":{},"source":["## Creating a Training Dataset"]},{"cell_type":"code","execution_count":null,"id":"9a0a1404-8e48-4ef1-8efc-aedfd941f710","metadata":{},"outputs":[],"source":["# CSV to Dataframe\n","traindays: DataFrame = spark.read \\\n","  .option(\"header\", \"true\") \\\n","  .csv('gs://{}/flights/trainday.csv'.format(BUCKET))\n","    \n","traindays.printSchema()"]},{"cell_type":"code","execution_count":null,"id":"eb25cbd0-cdc2-4ed6-96da-dbb027ce3fc2","metadata":{},"outputs":[],"source":["# Register the dataframe as TempView for spark sql\n","traindays.createOrReplaceTempView('traindays')\n","\n","spark.sql(\"SELECT * FROM traindays LIMIT 5\").show()"]},{"cell_type":"code","execution_count":null,"id":"0bc91ffe-a4d3-41af-b0d8-8becaedf46b3","metadata":{},"outputs":[],"source":["# Define the schema map from CSV to DataFrame\n","from pyspark.sql.types import StringType, FloatType, StructType, StructField\n","\n","header = 'FL_DATE,OP_UNIQUE_CARRIER,OP_CARRIER_AIRLINE_ID,OP_CARRIER,OP_CARRIER_FL_NUM,ORIGIN_AIRPORT_ID,'\n","header += 'ORIGIN_AIRPORT_SEQ_ID,ORIGIN_CITY_MARKET_ID,ORIGIN,DEST_AIRPORT_ID,'\n","header += 'DEST_AIRPORT_SEQ_ID,DEST_CITY_MARKET_ID,DEST,CRS_DEP_TIME,DEP_TIME,'\n","header += 'DEP_DELAY,TAXI_OUT,WHEELS_OFF,WHEELS_ON,TAXI_IN,'\n","header += 'CRS_ARR_TIME,ARR_TIME,ARR_DELAY,CANCELLED,'\n","header += 'CANCELLATION_CODE,DIVERTED,DISTANCE,DEP_AIRPORT_LAT,'\n","header += 'DEP_AIRPORT_LON,DEP_AIRPORT_TZOFFSET,ARR_AIRPORT_LAT,ARR_AIRPORT_LON,'\n","header += 'ARR_AIRPORT_TZOFFSET,EVENT,NOTIFY_TIME'\n","\n","print(header)\n","\n","def get_structfield(colname: str) -> StructField:\n","    if colname in ['ARR_DELAY', 'DEP_DELAY', 'DISTANCE', 'TAXI_OUT']:\n","        return StructField(colname, FloatType(), True)\n","    else:\n","        return StructField(colname, StringType(), True)\n","\n","\n","schema = StructType([get_structfield(colname) for colname in header.split(',')])"]},{"cell_type":"code","execution_count":null,"id":"c258e427-df70-46e3-90f7-6518eed1c319","metadata":{},"outputs":[],"source":["# Load data from google storage to spark\n","inputs = 'gs://{}/flights/tzcorr/flights-00000-*'.format(BUCKET)\n","# inputs = 'gs://{}/flights/tzcorr/flights-*'.format(BUCKET)\n","\n","flights: DataFrame = spark.read \\\n","  .schema(schema) \\\n","  .csv(inputs)\n","    \n","flights.createOrReplaceTempView('flights')"]},{"cell_type":"code","execution_count":null,"id":"3377a615-40c4-4eab-8399-c97e28e8d907","metadata":{},"outputs":[],"source":["# Load training dataset\n","trainquery: str = \"\"\"\n","SELECT\n","  f.*\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True'\n","\"\"\"\n","\n","traindata: DataFrame = spark.sql(trainquery)\n","traindata.head(2)"]},{"cell_type":"markdown","id":"7893db25-1081-457d-87ca-f1b98a2e3684","metadata":{},"source":["## Dealing with Corner Cases"]},{"cell_type":"code","execution_count":null,"id":"b7f1e140-2632-4d06-94e7-c38a7a23a8af","metadata":{},"outputs":[],"source":["# In order to procede to training data should be consistent.\n","# In this case, 'count' should be equivalent across all features.\n","# The data I want is the ones that taxied out and arrived at the airport.\n","traindata[[\"DEP_DELAY\", \"TAXI_OUT\", \"ARR_DELAY\", \"DISTANCE\"]].describe().show()"]},{"cell_type":"code","execution_count":null,"id":"2ac2c281-99f8-490e-80ac-5ed03220ec48","metadata":{},"outputs":[],"source":["# I will clean the odd values.\n","# Revise query by putting NULL fields into account\n","# Flights that were scheduled but \n","#   never left the gate (DEP_DELAY is null)\n","#   never take off (TAXI_OUT is null) \n","# Flights took off but diverted and do not have an ARR_DELAY (This includes TAXI_OUT)\n","# 'count' will now be all even.\n","trainquery: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," f.DEP_DELAY IS NOT NULL AND\n"," f.ARR_DELAY IS NOT NULL\n","\"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery)\n","traindata.describe().show()\n"]},{"cell_type":"code","execution_count":null,"id":"4f828d83-ded6-440e-8095-e551a1246315","metadata":{"scrolled":false},"outputs":[],"source":["# However, excluding NULL is fixing the problem at surface.\n","# It is recommended to fix the ROOT CAUSE of the context.\n","# In this case the root cause is \"canceled flights\" and \"divereted flights\"\n","\n","trainquery: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," f.CANCELLED == '0.00' AND\n"," f.DIVERTED == '0.00'\n"," \"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery)\n","traindata.describe().show()"]},{"cell_type":"code","execution_count":null,"id":"0ebb5d2d-1e40-4f82-b1d9-7573b0f0518f","metadata":{},"outputs":[],"source":["# Looks like there are still NULLs although we have excluded CACELLED and DIVERTED flights.\n","# Note: In the book it says that counts will be the same but in my case it was not so I still needed to exclude the NULLs.\n","trainquery: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," f.CANCELLED == '0.00' AND\n"," f.DIVERTED == '0.00' AND\n"," f.DEP_DELAY IS NOT NULL AND\n"," f.ARR_DELAY IS NOT NULL\n","\"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery)\n","traindata.describe().show()\n"]},{"cell_type":"markdown","id":"ace23e14-dc20-442e-a3be-50407985c559","metadata":{},"source":["## Creating Training Examples"]},{"cell_type":"code","execution_count":null,"id":"2c776609-8efe-48d1-ba2f-a14e73ac35ff","metadata":{},"outputs":[],"source":["# To use Logistic Regression (https://bit.ly/3HGBYpw)\n","# I first need labled training sets for binary outcomes.\n","# In this case , positive lable (1) and negative label(0)\n","# Note: https://spark.apache.org/docs/3.1.1/mllib-linear-methods.html#loss-functions\n","# Note that, in the mathematical formulation above, a binary label y is denoted as either +1 (positive) or −1 (negative), \n","# which is convenient for the formulation. \n","# However, the negative label is represented by 0 in spark.mllib instead of −1, to be consistent with multiclass labeling.\n","def to_example(raw_data_point: DataFrame) -> LabeledPoint:\n","    return LabeledPoint(\\\n","            float(raw_data_point['ARR_DELAY'] < 15),  # on-time? \\\n","            [ \\\n","                raw_data_point['DEP_DELAY'], \\\n","                raw_data_point['TAXI_OUT'], \\\n","                raw_data_point['DISTANCE'], \\\n","            ])\n","\n","examples: PipelinedRDD = traindata.rdd.map(to_example)"]},{"cell_type":"markdown","id":"67f7247c-925e-4df9-913c-4c8dad658266","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"id":"fc5e87f9-2c6b-4d9e-bc1c-a15aa388b527","metadata":{},"outputs":[],"source":["# Creating a model means finding out the weights\n","# w0*x0 + w1*x1 + w2*x2 + b\n","# intercept is set to True because prediction should not be 0 if x = 0\n","lrmodel: LogisticRegressionModel = LogisticRegressionWithLBFGS.train(examples, intercept=True)\n","    \n","print(lrmodel.weights,lrmodel.intercept)"]},{"cell_type":"code","execution_count":null,"id":"b6a63293-4bb3-4da7-9358-68b019c585ac","metadata":{},"outputs":[],"source":["# Example for positive\n","# DEP_DELAY, TAXI_OUT, DISTANCE\n","lrmodel.predict([6.0, 12.0, 594.0])"]},{"cell_type":"code","execution_count":null,"id":"6017b7a3-9321-4edc-80fa-bfca5bcf6ade","metadata":{},"outputs":[],"source":["# Example for negative\n","lrmodel.predict([36.0, 12.0, 594.0])"]},{"cell_type":"code","execution_count":null,"id":"c6f20c78-ab4b-4a29-80fe-1f753854f088","metadata":{},"outputs":[],"source":["# I want to see how probability is working out. To do that, I will need to clear the threshold.\n","lrmodel.clearThreshold()"]},{"cell_type":"code","execution_count":null,"id":"75be74bd-f147-40ec-bcef-452a2704fedf","metadata":{},"outputs":[],"source":["# Predict probability with fixed dep delay and taxi-out\n","dist: np.ndarray = np.arange(10, 2000, 10)\n","prob: list = [lrmodel.predict([20,10,d]) for d in dist]\n","plt.plot(dist, prob)"]},{"cell_type":"code","execution_count":null,"id":"fae81099-65cc-478e-bd8e-db81f94913fe","metadata":{},"outputs":[],"source":["# Predict probability with fixed taxi-out  and distance\n","delay: np.ndarray = np.arange(-20, 60, 1)\n","prob= list = [lrmodel.predict([d, 10, 500]) for d in delay]\n","ax = plt.plot(delay, prob)"]},{"cell_type":"code","execution_count":null,"id":"7e586eac-213c-453b-818d-b71cb902c94e","metadata":{},"outputs":[],"source":["# Okay. I now saw probability is predicted by changing the parameters.\n","# I will now set threshold to my goal and do the prediction.\n","# Set threshold for the probability to our goal\n","# Cancel flights if the probability of arriving flights are less than 70% \n","lrmodel.setThreshold(0.7)"]},{"cell_type":"markdown","id":"a3d11261-ba01-427d-adc4-0b4ed35d9b51","metadata":{},"source":["# Predicting by Using a Model"]},{"cell_type":"code","execution_count":null,"id":"f8857866-8f3f-4540-a471-de3e62c9950f","metadata":{},"outputs":[],"source":["# Save model to cloud stroage for future use\n","PREFIX = \"flights/sparkmloutput/model\"\n","MODEL_FILE: str = f\"gs://{BUCKET}/{PREFIX}\"\n","\n","client = storage.Client()\n","\n","blobs = [ f for f in client.list_blobs(BUCKET, prefix=PREFIX)]\n","\n","# Remove if any old model exist\n","if len(blobs) > 0:\n","    for blob in blobs:\n","        blob.delete()\n","        \n","lrmodel.save(sc, MODEL_FILE)\n","\n","# Predict from saved model in google storage\n","from pyspark.mllib.classification import LogisticRegressionModel\n","lrmodel: LogisticRegressionModel = LogisticRegressionModel.load(sc, MODEL_FILE)\n","\n","# Set decision threshold to 70%\n","lrmodel.setThreshold(0.7)\n","\n","# Try out sample\n","print(lrmodel.predict([36.0, 12.0, 594.0]))"]},{"cell_type":"markdown","id":"036a33fb","metadata":{},"source":["# Evaluating a Model"]},{"cell_type":"code","execution_count":null,"id":"f24e1fa4","metadata":{},"outputs":[],"source":["# Evaluation will be done using the test data instead of training data\n","# Use non test days for evaluation\n","testquery: str = trainquery.replace(\"t.is_train_day == 'True'\", \"t.is_train_day == 'False'\")\n","    \n","# Label the dataset\n","testdata: DataFrame = spark.sql(testquery)\n","examples: PipelinedRDD = testdata.rdd.map(to_example)\n","    \n","# Predict\n","labelpred: PipelinedRDD = examples.map(lambda lp: (lp.label, lrmodel.predict(lp.features)))\n","\n","# Print first 10 elements for confirmation\n","labelpred.take(10)"]},{"cell_type":"code","execution_count":null,"id":"f008cfb5","metadata":{},"outputs":[],"source":["# Layout statistics for evaluation\n","def eval(labelpred: PipelinedRDD):\n","    \"\"\"\n","    labelpred[0]: Actual\n","    labelpred[1]: Prediction\n","    \"\"\"\n","\n","    # Predicted as positive\n","    cancel: PipelinedRDD = labelpred.filter(lambda lp: lp[1] == 1)\n","\n","    # Predicted as negative\n","    nocancel: PipelinedRDD = labelpred.filter(lambda lp: lp[1] == 0)\n","\n","    # Out of all positive predicted results , count the ones that are actually positive\n","    corr_cancel = cancel.filter(lambda lp: lp[0] == lp[1]).count()\n","\n","    # Out of all positive predicted results , count the ones that are actually negative\n","    corr_nocancel = nocancel.filter(lambda lp: lp[0] == lp[1]).count()  \n","    \n","    print(f\"Predicted as canceled: {cancel.count()}\")\n","    print(f\"Predicted as noncancel: {nocancel.count()}\")\n","    print(f\"Correctly labeled canceled: {corr_cancel}\")\n","    print(f\"Correctly labeled not canceled: {corr_nocancel}\")\n","    \n","    return {\n","        'total_cancel': cancel.count(),\n","        'correct_cancel': float(corr_cancel)/cancel.count(),\n","        'total_nocancel': nocancel.count(),\n","        'correct_nocancel': float(corr_nocancel)/nocancel.count()\n","    }\n","\n","print(eval(labelpred))"]},{"cell_type":"code","execution_count":null,"id":"abd039fb","metadata":{},"outputs":[],"source":["# Revised evaluation. Based on porbability instead of categorical prediction.\n","def eval_revised(labelpred: namedtuple):\n","    \"\"\"\n","    labelpred[0]: Actual\n","    labelpred[1]: Prediction\n","    \"\"\"\n","    # Canceled which probability is below 0.7\n","    cancel: PipelinedRDD = labelpred.filter(lambda lp: lp[1] < 0.7)\n","\n","    # No cacelation which probability is greater than equal 0.7\n","    nocancel: PipelinedRDD = labelpred.filter(lambda lp: lp[1] >= 0.7)\n","\n","    corr_cancel = cancel.filter(lambda lp: lp[0] == int(lp[1] < 0.7)).count()\n","    corr_nocancel = nocancel.filter(lambda lp: lp[0] == int(lp[1] >= 0.7)).count()\n","    \n","    # RMSE\n","    totsqe: PipelinedRDD = labelpred.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum()\n","\n","    print(f\"Predicted as canceled: {cancel.count()}\")\n","    print(f\"Predicted as noncancel: {nocancel.count()}\")\n","    print(f\"Correctly labeled canceled: {corr_cancel}\")\n","    print(f\"Correctly labeled not canceled: {corr_nocancel}\")\n","    \n","    return {\n","        'total_cancel': cancel.count(),\n","        'correct_cancel': float(corr_cancel)/cancel.count(),\n","        'total_nocancel': nocancel.count(),\n","        'correct_nocancel': float(corr_nocancel)/nocancel.count(),\n","        'rmse': np.sqrt(totsqe/float(corr_cancel + corr_nocancel))\n","    }"]},{"cell_type":"code","execution_count":null,"id":"380843c9","metadata":{},"outputs":[],"source":["lrmodel.clearThreshold() # so it returns probabilities\n","\n","# Predict\n","labelpred: PipelinedRDD = examples.map(lambda lp: (lp.label, lrmodel.predict(lp.features)))\n","print(eval_revised(labelpred))\n","\n","# keep only those examples near the decision threshold\n","labelpred: PipelinedRDD = labelpred.filter(lambda p: p[1] > 0.65 and p[1] < 0.75)\n","print(eval_revised(labelpred))"]},{"cell_type":"markdown","id":"c66601c7","metadata":{},"source":["## Experimental framework"]},{"cell_type":"markdown","id":"01cce73c","metadata":{},"source":["So far the probability is looks okay if 71% chance of arriving at least 15 min early.\n","I will verfiy this by doing feature selection. \n","But first I will set RMSE to choose between models. Model that has better RMSE will be chosen.\n","As the book says, unless 0.5 % decrease with RMSE, feature will not be changed."]},{"cell_type":"markdown","id":"a664b140","metadata":{},"source":["## Creating the Held-Out Dataset"]},{"cell_type":"markdown","id":"89d558c3","metadata":{},"source":["First prepare three types of data set\n","\n","| Dataset type | Conditional |\n","| ------------ | ----------- |\n","| Training   | is_train_day == True, holdout == False |\n","| Held out   | is_train_dat == True, holdout == True |\n","| Test | is_train_day == False |"]},{"cell_type":"code","execution_count":null,"id":"069065b9","metadata":{},"outputs":[],"source":["# Mark random 20 % of training dataset as held out dataset\n","from pyspark.sql.functions import rand\n","\n","SEED: int = 13\n","traindays = traindays.withColumn(\"holdout\", rand(SEED) > 0.8)\n","traindays.createOrReplaceTempView('traindays')\n","\n","traindays.show()\n","\n","trainquery: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," t.holdout == False AND\n"," f.CANCELLED == '0.00' AND\n"," f.DIVERTED == '0.00' AND\n"," f.DEP_DELAY IS NOT NULL AND\n"," f.ARR_DELAY IS NOT NULL\n","\"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery)\n","    \n","# This will be the query to fetch data for feature selection\n","heldout_query: str = trainquery.replace(\"t.holdout == False\", \"t.holdout == True\")\n","heldout_data: DataFrame = spark.sql(heldout_query)"]},{"cell_type":"markdown","id":"c4c858b0","metadata":{},"source":["## Feature Selection"]},{"cell_type":"code","execution_count":null,"id":"e3eb870f","metadata":{},"outputs":[],"source":["# 1st seletion : Excluding TAXI_OUT\n","def to_example(raw_data_point: dict):\n","    return LabeledPoint(\n","        float(raw_data_point['ARR_DELAY'] < 15), # ontime\n","        [\n","            raw_data_point['DEP_DELAY'], # DEP_DELAY\n","            raw_data_point['DISTANCE'] # DEP_DISTANCE,\n","        ]\n","    )\n","\n","# Train\n","examples: PipelinedRDD = traindata.rdd.map(to_example)\n","lrmodel: LogisticRegressionModel = LogisticRegressionWithLBFGS.train(examples, intercept=True)\n","lrmodel.clearThreshold() # so it returns probabilities\n","\n","# Predict\n","examples: PipelinedRDD = heldout_data.rdd.map(to_example)\n","labelpred: PipelinedRDD = examples.map(lambda lp: (lp.label, lrmodel.predict(lp.features)))\n","labelpred: PipelinedRDD = labelpred.filter(lambda p: p[1] > 0.65 and p[1] < 0.75)\n","\n","# Evaluate\n","print(eval_revised(labelpred))"]},{"cell_type":"code","execution_count":null,"id":"787f794f","metadata":{},"outputs":[],"source":["# 2nd seletion : Excluding DEP_DELAY\n","def to_example(raw_data_point: dict):\n","    return LabeledPoint(\n","        float(raw_data_point['ARR_DELAY'] < 15), # ontime\n","        [\n","                raw_data_point['TAXI_OUT'], \\\n","                raw_data_point['DISTANCE'], \\\n","        ]\n","    )\n","\n","# Train\n","examples: PipelinedRDD = traindata.rdd.map(to_example)\n","lrmodel: LogisticRegressionModel = LogisticRegressionWithLBFGS.train(examples, intercept=True)\n","lrmodel.clearThreshold() # so it returns probabilities\n","    \n","# Predict\n","examples: PipelinedRDD = heldout_data.rdd.map(to_example)\n","labelpred: PipelinedRDD = examples.map(lambda lp: (lp.label, lrmodel.predict(lp.features)))\n","labelpred: PipelinedRDD = labelpred.filter(lambda p: p[1] > 0.65 and p[1] < 0.75)\n","    \n","# Evaluate\n","print(eval_revised(labelpred))"]},{"cell_type":"code","execution_count":null,"id":"a9c603f6","metadata":{},"outputs":[],"source":["# 3rd seletion : Excluding DISTANCE\n","def to_example(raw_data_point: dict):\n","    return LabeledPoint(\n","        float(raw_data_point['ARR_DELAY'] < 15), # ontime\n","        [\n","                raw_data_point['DEP_DELAY'], \\\n","                raw_data_point['TAXI_OUT'],\n","        ]\n","    )\n","\n","# Train\n","examples: PipelinedRDD = traindata.rdd.map(to_example)\n","lrmodel: LogisticRegressionModel = LogisticRegressionWithLBFGS.train(examples, intercept=True)\n","lrmodel.clearThreshold() # so it returns probabilities\n","    \n","# Predict\n","examples: PipelinedRDD = heldout_data.rdd.map(to_example)\n","labelpred: PipelinedRDD = examples.map(lambda lp: (lp.label, lrmodel.predict(lp.features)))\n","labelpred: PipelinedRDD = labelpred.filter(lambda p: p[1] > 0.65 and p[1] < 0.75)\n","    \n","# Evaluate\n","print(eval_revised(labelpred))"]},{"cell_type":"markdown","id":"34cca19b","metadata":{},"source":["Result\n","\n","Looks like RMSE was not reduced in any of the pattern.\n","\n","| Pattern | RMSE | Percent increase |\n","| ------- | ---- | ---------------- |\n","| Full set | 0.252742459141375 | |\n","| Removed TAXI_OUT | 0.3488991171205433 | 38% |\n","| Removed DEP_DELAY | 0.5200556625529862 | 105% | \n","| Removed DISTANCE | 0.31710244140962074 | 25% |"]},{"cell_type":"markdown","id":"a3fa0f60","metadata":{},"source":["## Scaling"]},{"cell_type":"code","execution_count":null,"id":"a1499364","metadata":{},"outputs":[],"source":["# ToDO Different RMSE from initial experiment with 3 features\n","# Scailng is to scale the feature variables to similar magnitude.\n","# This will help the regression library to choose initial weight effective manner.\n","\n","def to_example(raw_data_point):\n","    return LabeledPoint(\n","        float(raw_data_point['DEP_DELAY'] < 15), #ontime\n","        [\n","            raw_data_point['DEP_DELAY'] / 30,\n","            (raw_data_point['DISTANCE'] / 1000) - 1,\n","            (raw_data_point['TAXI_OUT'] / 10) - 1\n","        ]\n","    )\n","\n","# Train\n","traindata: DataFrame = spark.sql(trainquery)\n","examples: PipelinedRDD = traindata.rdd.map(to_example)\n","lrmodel: LogisticRegressionModel = LogisticRegressionWithLBFGS.train(examples, intercept=True)\n","lrmodel.clearThreshold() # so it returns probabilities\n","   \n","# Predict\n","testquery: str = trainquery.replace(\"t.is_train_day == 'True'\", \"t.is_train_day == 'False'\")\n","    \n","# Label the dataset\n","testdata: DataFrame = spark.sql(testquery)\n","examples: PipelinedRDD = testdata.rdd.map(to_example)\n","labelpred: PipelinedRDD = examples.map(lambda lp: (lp.label, lrmodel.predict(lp.features)))\n","#labelpred: PipelinedRDD = labelpred.filter(lambda p: p[1] > 0.65 and p[1] < 0.75)\n","    \n","# Evaluate\n","print(eval_revised(labelpred))"]},{"cell_type":"code","execution_count":null,"id":"511432a9","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}