{"cells": [{"cell_type": "code", "execution_count": 2, "id": "1a456ff7-140b-4304-abcd-f448eff4dcb6", "metadata": {}, "outputs": [], "source": "# Static variables\nBUCKET='elite-caster-125113'"}, {"cell_type": "code", "execution_count": 3, "id": "00d224a1-74af-4587-84b1-2bafd96d5519", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.dataframe import DataFrame\nspark = SparkSession\\\n  .builder \\\n  .appName(\"Lgistic regression w/ Spark ML\") \\\n  .getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "id": "bd6f1673-ab02-447e-aca1-27700c82527e", "metadata": {}, "outputs": [], "source": "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\nfrom pyspark.mllib.regression import LabeledPoint"}, {"cell_type": "markdown", "id": "f86ebc78-9a2f-464a-91d1-f4d92395448d", "metadata": {}, "source": "## Creating a Training Dataset"}, {"cell_type": "code", "execution_count": 6, "id": "9a0a1404-8e48-4ef1-8efc-aedfd941f710", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# CSV to Dataframe\ntraindays: DataFrame = spark.read \\\n  .option(\"header\", \"true\") \\\n  .csv('gs://{}/flights/trainday.csv'.format(BUCKET))"}, {"cell_type": "code", "execution_count": 7, "id": "c42b5748-84bb-4ad1-91e8-283362535167", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- FL_DATE: string (nullable = true)\n |-- is_train_day: string (nullable = true)\n\n"}], "source": "traindays.printSchema()"}, {"cell_type": "code", "execution_count": 8, "id": "eb25cbd0-cdc2-4ed6-96da-dbb027ce3fc2", "metadata": {}, "outputs": [], "source": "# Register the dataframe as TempView for spark sql\ntraindays.createOrReplaceTempView('traindays')"}, {"cell_type": "code", "execution_count": 9, "id": "7fb2605c-160e-4f4b-9afc-51f704d046ec", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 2:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------------+\n|   FL_DATE|is_train_day|\n+----------+------------+\n|2018-01-02|        True|\n|2018-01-03|        True|\n|2018-01-04|        True|\n|2018-01-05|        True|\n|2018-01-07|        True|\n+----------+------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql(\"SELECT * FROM traindays LIMIT 5\").show()"}, {"cell_type": "code", "execution_count": 16, "id": "0bc91ffe-a4d3-41af-b0d8-8becaedf46b3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "FL_DATE,OP_UNIQUE_CARRIER,OP_CARRIER_AIRLINE_ID,OP_CARRIER,OP_CARRIER_FL_NUM,ORIGIN_AIRPORT_ID,ORIGIN_AIRPORT_SEQ_ID,ORIGIN_CITY_MARKET_ID,ORIGIN,DEST_AIRPORT_ID,DEST_AIRPORT_SEQ_ID,DEST_CITY_MARKET_ID,DEST,CRS_DEP_TIME,DEP_TIME,DEP_DELAY,TAXI_OUT,WHEELS_OFF,WHEELS_ON,TAXI_IN,CRS_ARR_TIME,ARR_TIME,ARR_DELAY,CANCELLED,CANCELLATION_CODE,DIVERTED,DISTANCE,DEP_AIRPORT_LAT,DEP_AIRPORT_LON,DEP_AIRPORT_TZOFFSET,ARR_AIRPORT_LAT,ARR_AIRPORT_LON,ARR_AIRPORT_TZOFFSET,EVENT,NOTIFY_TIME\n"}], "source": "from pyspark.sql.types import StringType, FloatType, StructType, StructField\n\nheader = 'FL_DATE,OP_UNIQUE_CARRIER,OP_CARRIER_AIRLINE_ID,OP_CARRIER,OP_CARRIER_FL_NUM,ORIGIN_AIRPORT_ID,'\nheader += 'ORIGIN_AIRPORT_SEQ_ID,ORIGIN_CITY_MARKET_ID,ORIGIN,DEST_AIRPORT_ID,'\nheader += 'DEST_AIRPORT_SEQ_ID,DEST_CITY_MARKET_ID,DEST,CRS_DEP_TIME,DEP_TIME,'\nheader += 'DEP_DELAY,TAXI_OUT,WHEELS_OFF,WHEELS_ON,TAXI_IN,'\nheader += 'CRS_ARR_TIME,ARR_TIME,ARR_DELAY,CANCELLED,'\nheader += 'CANCELLATION_CODE,DIVERTED,DISTANCE,DEP_AIRPORT_LAT,'\nheader += 'DEP_AIRPORT_LON,DEP_AIRPORT_TZOFFSET,ARR_AIRPORT_LAT,ARR_AIRPORT_LON,'\nheader += 'ARR_AIRPORT_TZOFFSET,EVENT,NOTIFY_TIME'\n\nprint(header)\n\ndef get_structfield(colname: str) -> StructField:\n    if colname in ['ARR_DELAY', 'DEP_DELAY', 'DISTANCE', 'TAXI_OUT']:\n        return StructField(colname, FloatType(), True)\n    else:\n        return StructField(colname, StringType(), True)\n\n\nschema = StructType([get_structfield(colname) for colname in header.split(',')])"}, {"cell_type": "code", "execution_count": 11, "id": "6b672c23-85ff-4485-b606-dbe17ce93435", "metadata": {}, "outputs": [], "source": "inputs = 'gs://{}/flights/tzcorr/flights-00000-*'.format(BUCKET)\n# inputs = 'gs://{}/flights/tzcorr/flights-*'.format(BUCKET)"}, {"cell_type": "code", "execution_count": 15, "id": "c258e427-df70-46e3-90f7-6518eed1c319", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- FL_DATE: string (nullable = true)\n |-- OP_UNIQUE_CARRIER: string (nullable = true)\n |-- OP_CARRIER_AIRLINE_ID: string (nullable = true)\n |-- OP_CARRIER: string (nullable = true)\n |-- OP_CARRIER_FL_NUM: string (nullable = true)\n |-- ORIGIN_AIRPORT_ID: string (nullable = true)\n |-- ORIGIN_AIRPORT_SEQ_ID: string (nullable = true)\n |-- ORIGIN_CITY_MARKET_ID: string (nullable = true)\n |-- ORIGIN: string (nullable = true)\n |-- DEST_AIRPORT_ID: string (nullable = true)\n |-- DEST_AIRPORT_SEQ_ID: string (nullable = true)\n |-- DEST_CITY_MARKET_ID: string (nullable = true)\n |-- DEST: string (nullable = true)\n |-- CRS_DEP_TIME: string (nullable = true)\n |-- DEP_TIME: string (nullable = true)\n |-- DEP_DELAY: float (nullable = true)\n |-- TAXI_OUT: float (nullable = true)\n |-- WHEELS_OFF: string (nullable = true)\n |-- WHEELS_ON: string (nullable = true)\n |-- TAXI_IN: string (nullable = true)\n |-- CRS_ARR_TIME: string (nullable = true)\n |-- ARR_TIME: string (nullable = true)\n |-- ARR_DELAY: float (nullable = true)\n |-- CANCELLED: string (nullable = true)\n |-- CANCELLATION_CODE: string (nullable = true)\n |-- DIVERTED: string (nullable = true)\n |-- DISTANCE: float (nullable = true)\n |-- DEP_AIRPORT_LAT: string (nullable = true)\n |-- DEP_AIRPORT_LON: string (nullable = true)\n |-- DEP_AIRPORT_TZOFFSET: string (nullable = true)\n |-- ARR_AIRPORT_LAT: string (nullable = true)\n |-- ARR_AIRPORT_LON: string (nullable = true)\n |-- ARR_AIRPORT_TZOFFSET: string (nullable = true)\n |-- EVENT: string (nullable = true)\n |-- NOTIFY_TIME: string (nullable = true)\n\n"}], "source": "flights: DataFrame = spark.read \\\n  .schema(schema) \\\n  .csv(inputs)\n    \nflights.createOrReplaceTempView('flights')"}, {"cell_type": "code", "execution_count": 13, "id": "3377a615-40c4-4eab-8399-c97e28e8d907", "metadata": {}, "outputs": [], "source": "trainquery: str = \"\"\"\nSELECT\n  f.*\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n t.is_train_day == 'True'\n\"\"\"\n\ntraindata: DataFrame = spark.sql(trainquery)"}, {"cell_type": "markdown", "id": "7893db25-1081-457d-87ca-f1b98a2e3684", "metadata": {}, "source": "## Dealing with Corner Cases"}, {"cell_type": "code", "execution_count": 14, "id": "a56afa09-f935-4eed-9661-9531c9095921", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "[Row(FL_DATE='2018-01-02', OP_UNIQUE_CARRIER='9E', OP_CARRIER_AIRLINE_ID='20363', OP_CARRIER='9E', OP_CARRIER_FL_NUM='3615', ORIGIN_AIRPORT_ID='11898', ORIGIN_AIRPORT_SEQ_ID='1189802', ORIGIN_CITY_MARKET_ID='31898', ORIGIN='GFK', DEST_AIRPORT_ID='13487', DEST_AIRPORT_SEQ_ID='1348702', DEST_CITY_MARKET_ID='31650', DEST='MSP', CRS_DEP_TIME='2018-01-02 19:10:00', DEP_TIME='2018-01-02 19:05:00', DEP_DELAY=-5.0, TAXI_OUT=10.0, WHEELS_OFF='2018-01-02 19:15:00', WHEELS_ON='2018-01-02 20:02:00', TAXI_IN='5.00', CRS_ARR_TIME='2018-01-02 20:29:00', ARR_TIME='2018-01-02 20:07:00', ARR_DELAY=-22.0, CANCELLED='0.00', CANCELLATION_CODE=None, DIVERTED='0.00', DISTANCE=284.0, DEP_AIRPORT_LAT='47.94722222', DEP_AIRPORT_LON='-97.17388889', DEP_AIRPORT_TZOFFSET='-21600.0', ARR_AIRPORT_LAT='44.88194444', ARR_AIRPORT_LON='-93.22166667', ARR_AIRPORT_TZOFFSET='-21600.0', EVENT=None, NOTIFY_TIME=None),\n Row(FL_DATE='2018-01-02', OP_UNIQUE_CARRIER='9E', OP_CARRIER_AIRLINE_ID='20363', OP_CARRIER='9E', OP_CARRIER_FL_NUM='3615', ORIGIN_AIRPORT_ID='13487', ORIGIN_AIRPORT_SEQ_ID='1348702', ORIGIN_CITY_MARKET_ID='31650', ORIGIN='MSP', DEST_AIRPORT_ID='11898', DEST_AIRPORT_SEQ_ID='1189802', DEST_CITY_MARKET_ID='31898', DEST='GFK', CRS_DEP_TIME='2018-01-02 17:15:00', DEP_TIME='2018-01-02 17:14:00', DEP_DELAY=-1.0, TAXI_OUT=24.0, WHEELS_OFF='2018-01-02 17:38:00', WHEELS_ON='2018-01-02 18:31:00', TAXI_IN='6.00', CRS_ARR_TIME='2018-01-02 18:45:00', ARR_TIME='2018-01-02 18:37:00', ARR_DELAY=-8.0, CANCELLED='0.00', CANCELLATION_CODE=None, DIVERTED='0.00', DISTANCE=284.0, DEP_AIRPORT_LAT='44.88194444', DEP_AIRPORT_LON='-93.22166667', DEP_AIRPORT_TZOFFSET='-21600.0', ARR_AIRPORT_LAT='47.94722222', ARR_AIRPORT_LON='-97.17388889', ARR_AIRPORT_TZOFFSET='-21600.0', EVENT=None, NOTIFY_TIME=None)]"}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": "traindata.head(2)"}, {"cell_type": "code", "execution_count": 20, "id": "b7f1e140-2632-4d06-94e7-c38a7a23a8af", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 14:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------------------+------------------+-----------------+-----------------+\n|summary|         DEP_DELAY|          TAXI_OUT|        ARR_DELAY|         DISTANCE|\n+-------+------------------+------------------+-----------------+-----------------+\n|  count|            104732|            104792|           104464|           111534|\n|   mean|13.306744834434557|17.099101076418048|6.268293383366519|815.3889576272707|\n| stddev| 52.23925364755955| 9.644846467745014|53.40158784227428|605.3003644466102|\n|    min|             -49.0|               1.0|            -78.0|             31.0|\n|    max|            1752.0|             164.0|           1778.0|           4983.0|\n+-------+------------------+------------------+-----------------+-----------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "traindata[[\"DEP_DELAY\", \"TAXI_OUT\", \"ARR_DELAY\", \"DISTANCE\"]].describe().show()"}, {"cell_type": "code", "execution_count": 22, "id": "2ac2c281-99f8-490e-80ac-5ed03220ec48", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 18:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------------------+------------------+------------------+-----------------+\n|summary|         DEP_DELAY|          TAXI_OUT|         ARR_DELAY|         DISTANCE|\n+-------+------------------+------------------+------------------+-----------------+\n|  count|            104348|            104348|            104348|           104348|\n|   mean|13.169586384022693|17.083997776670373|6.2886686855521905|813.5318261969563|\n| stddev| 51.35008338509632|  9.63459230131671|53.425693453588465|602.6741231081046|\n|    min|             -49.0|               1.0|             -78.0|             31.0|\n|    max|            1752.0|             164.0|            1778.0|           4983.0|\n+-------+------------------+------------------+------------------+-----------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Revise query by putting NULL fields into account\n# Flights that were scheduled but \n#   never left the gate (DEP_DELAY is null)\n#   never take off (TAXI_OUT is null) \n# Flights took off but diverted and do not have an ARR_DELAY (This includes TAXI_OUT)\ntrainquery_revised: str = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n t.is_train_day == 'True' AND\n f.DEP_DELAY IS NOT NULL AND\n f.ARR_DELAY IS NOT NULL\n\"\"\"\n    \ntraindata: DataFrame = spark.sql(trainquery_revised)\ntraindata.describe().show()\n"}, {"cell_type": "code", "execution_count": 24, "id": "0ebb5d2d-1e40-4f82-b1d9-7573b0f0518f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 22:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------------------+------------------+-----------------+-----------------+\n|summary|         DEP_DELAY|          TAXI_OUT|        ARR_DELAY|         DISTANCE|\n+-------+------------------+------------------+-----------------+-----------------+\n|  count|            104379|            104497|           104464|           104497|\n|   mean|13.166470267007732|17.091227499354048|6.268293383366519|813.0437811611816|\n| stddev| 51.34305436913121| 9.639548229308126|53.40158784227428|602.4833101721217|\n|    min|             -49.0|               1.0|            -78.0|             31.0|\n|    max|            1752.0|             164.0|           1778.0|           4983.0|\n+-------+------------------+------------------+-----------------+-----------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# I want to fix the root cause instead of fixing the symptom\ntrainquery_revised_final: str = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n t.is_train_day == 'True' AND\n f.CANCELLED == '0.00' AND\n f.DIVERTED == '0.00'\n\"\"\"\n    \ntraindata: DataFrame = spark.sql(trainquery_revised_final)\ntraindata.describe().show()\n"}, {"cell_type": "markdown", "id": "ace23e14-dc20-442e-a3be-50407985c559", "metadata": {}, "source": "## Creating Training Examples"}, {"cell_type": "code", "execution_count": 27, "id": "2c776609-8efe-48d1-ba2f-a14e73ac35ff", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# To use Logistic Regression (https://bit.ly/3HGBYpw)\n# I first need labled training sets for binary outcomes.\n# In this case , positive lable (1) and negative label(0)\ndef to_example(raw_data_point: DataFrame) -> LabeledPoint:\n    return LabeledPoint(\\\n            float(raw_data_point['ARR_DELAY'] < 15),  # on-time? \\\n            [ \\\n                raw_data_point['DEP_DELAY'], \\\n                raw_data_point['TAXI_OUT'], \\\n                raw_data_point['DISTANCE'], \\\n            ])\n\nexamples: DataFrame = traindata.rdd.map(to_example)"}, {"cell_type": "markdown", "id": "67f7247c-925e-4df9-913c-4c8dad658266", "metadata": {}, "source": "## Training"}, {"cell_type": "code", "execution_count": null, "id": "fc5e87f9-2c6b-4d9e-bc1c-a15aa388b527", "metadata": {}, "outputs": [], "source": "# tbc"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}