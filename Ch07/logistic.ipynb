{"cells":[{"cell_type":"code","execution_count":null,"id":"1a456ff7-140b-4304-abcd-f448eff4dcb6","metadata":{},"outputs":[],"source":["# Static variables\n","BUCKET='elite-caster-125113'"]},{"cell_type":"code","execution_count":null,"id":"00d224a1-74af-4587-84b1-2bafd96d5519","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.dataframe import DataFrame\n","spark = SparkSession\\\n","  .builder \\\n","  .appName(\"Lgistic regression w/ Spark ML\") \\\n","  .getOrCreate()"]},{"cell_type":"code","execution_count":null,"id":"bd6f1673-ab02-447e-aca1-27700c82527e","metadata":{},"outputs":[],"source":["from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n","from pyspark.mllib.regression import LabeledPoint\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","id":"f86ebc78-9a2f-464a-91d1-f4d92395448d","metadata":{},"source":["## Creating a Training Dataset"]},{"cell_type":"code","execution_count":null,"id":"9a0a1404-8e48-4ef1-8efc-aedfd941f710","metadata":{},"outputs":[],"source":["# CSV to Dataframe\n","traindays: DataFrame = spark.read \\\n","  .option(\"header\", \"true\") \\\n","  .csv('gs://{}/flights/trainday.csv'.format(BUCKET))"]},{"cell_type":"code","execution_count":null,"id":"c42b5748-84bb-4ad1-91e8-283362535167","metadata":{},"outputs":[],"source":["traindays.printSchema()"]},{"cell_type":"code","execution_count":null,"id":"eb25cbd0-cdc2-4ed6-96da-dbb027ce3fc2","metadata":{},"outputs":[],"source":["# Register the dataframe as TempView for spark sql\n","traindays.createOrReplaceTempView('traindays')"]},{"cell_type":"code","execution_count":null,"id":"7fb2605c-160e-4f4b-9afc-51f704d046ec","metadata":{},"outputs":[],"source":["spark.sql(\"SELECT * FROM traindays LIMIT 5\").show()"]},{"cell_type":"code","execution_count":null,"id":"0bc91ffe-a4d3-41af-b0d8-8becaedf46b3","metadata":{},"outputs":[],"source":["from pyspark.sql.types import StringType, FloatType, StructType, StructField\n","\n","header = 'FL_DATE,OP_UNIQUE_CARRIER,OP_CARRIER_AIRLINE_ID,OP_CARRIER,OP_CARRIER_FL_NUM,ORIGIN_AIRPORT_ID,'\n","header += 'ORIGIN_AIRPORT_SEQ_ID,ORIGIN_CITY_MARKET_ID,ORIGIN,DEST_AIRPORT_ID,'\n","header += 'DEST_AIRPORT_SEQ_ID,DEST_CITY_MARKET_ID,DEST,CRS_DEP_TIME,DEP_TIME,'\n","header += 'DEP_DELAY,TAXI_OUT,WHEELS_OFF,WHEELS_ON,TAXI_IN,'\n","header += 'CRS_ARR_TIME,ARR_TIME,ARR_DELAY,CANCELLED,'\n","header += 'CANCELLATION_CODE,DIVERTED,DISTANCE,DEP_AIRPORT_LAT,'\n","header += 'DEP_AIRPORT_LON,DEP_AIRPORT_TZOFFSET,ARR_AIRPORT_LAT,ARR_AIRPORT_LON,'\n","header += 'ARR_AIRPORT_TZOFFSET,EVENT,NOTIFY_TIME'\n","\n","print(header)\n","\n","def get_structfield(colname: str) -> StructField:\n","    if colname in ['ARR_DELAY', 'DEP_DELAY', 'DISTANCE', 'TAXI_OUT']:\n","        return StructField(colname, FloatType(), True)\n","    else:\n","        return StructField(colname, StringType(), True)\n","\n","\n","schema = StructType([get_structfield(colname) for colname in header.split(',')])"]},{"cell_type":"code","execution_count":null,"id":"6b672c23-85ff-4485-b606-dbe17ce93435","metadata":{},"outputs":[],"source":["inputs = 'gs://{}/flights/tzcorr/flights-00000-*'.format(BUCKET)\n","# inputs = 'gs://{}/flights/tzcorr/flights-*'.format(BUCKET)"]},{"cell_type":"code","execution_count":null,"id":"c258e427-df70-46e3-90f7-6518eed1c319","metadata":{},"outputs":[],"source":["flights: DataFrame = spark.read \\\n","  .schema(schema) \\\n","  .csv(inputs)\n","    \n","flights.createOrReplaceTempView('flights')"]},{"cell_type":"code","execution_count":null,"id":"3377a615-40c4-4eab-8399-c97e28e8d907","metadata":{},"outputs":[],"source":["trainquery: str = \"\"\"\n","SELECT\n","  f.*\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True'\n","\"\"\"\n","\n","traindata: DataFrame = spark.sql(trainquery)"]},{"cell_type":"markdown","id":"7893db25-1081-457d-87ca-f1b98a2e3684","metadata":{},"source":["## Dealing with Corner Cases"]},{"cell_type":"code","execution_count":null,"id":"a56afa09-f935-4eed-9661-9531c9095921","metadata":{},"outputs":[],"source":["traindata.head(2)"]},{"cell_type":"code","execution_count":null,"id":"b7f1e140-2632-4d06-94e7-c38a7a23a8af","metadata":{},"outputs":[],"source":["traindata[[\"DEP_DELAY\", \"TAXI_OUT\", \"ARR_DELAY\", \"DISTANCE\"]].describe().show()"]},{"cell_type":"code","execution_count":null,"id":"2ac2c281-99f8-490e-80ac-5ed03220ec48","metadata":{},"outputs":[],"source":["# Revise query by putting NULL fields into account\n","# Flights that were scheduled but \n","#   never left the gate (DEP_DELAY is null)\n","#   never take off (TAXI_OUT is null) \n","# Flights took off but diverted and do not have an ARR_DELAY (This includes TAXI_OUT)\n","trainquery_revised: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," f.DEP_DELAY IS NOT NULL AND\n"," f.ARR_DELAY IS NOT NULL\n","\"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery_revised)\n","traindata.describe().show()\n"]},{"cell_type":"code","execution_count":null,"id":"4f828d83-ded6-440e-8095-e551a1246315","metadata":{},"outputs":[],"source":["# I want to fix the root cause instead of fixing the symptom\n","# See if there are really no NULLs\n","trainquery_revised_test: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," f.CANCELLED == '0.00' AND\n"," f.DIVERTED == '0.00' AND\n"," (f.DEP_DELAY IS NULL) OR\n"," (f.ARR_DELAY IS NULL)\n","\"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery_revised_test)\n","traindata.head(5)"]},{"cell_type":"code","execution_count":null,"id":"0ebb5d2d-1e40-4f82-b1d9-7573b0f0518f","metadata":{},"outputs":[],"source":["# Lookds like there still NULLs although we have excluded CACELLED and DIVERTED flights.\n","# Note: In the book it says that counts will be the same but in my caee it was not so I still needed to exclude the NULLs.\n","trainquery_revised_final: str = \"\"\"\n","SELECT\n","  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n","FROM flights f\n","JOIN traindays t\n","ON f.FL_DATE == t.FL_DATE\n","WHERE\n"," t.is_train_day == 'True' AND\n"," f.CANCELLED == '0.00' AND\n"," f.DIVERTED == '0.00' AND\n"," f.DEP_DELAY IS NOT NULL AND\n"," f.ARR_DELAY IS NOT NULL\n","\"\"\"\n","    \n","traindata: DataFrame = spark.sql(trainquery_revised_final)\n","traindata.describe().show()\n"]},{"cell_type":"markdown","id":"ace23e14-dc20-442e-a3be-50407985c559","metadata":{},"source":["## Creating Training Examples"]},{"cell_type":"code","execution_count":null,"id":"2c776609-8efe-48d1-ba2f-a14e73ac35ff","metadata":{},"outputs":[],"source":["# To use Logistic Regression (https://bit.ly/3HGBYpw)\n","# I first need labled training sets for binary outcomes.\n","# In this case , positive lable (1) and negative label(0)\n","# Note: https://spark.apache.org/docs/3.1.1/mllib-linear-methods.html#loss-functions\n","# Note that, in the mathematical formulation above, a binary label y is denoted as either +1 (positive) or −1 (negative), \n","# which is convenient for the formulation. \n","# However, the negative label is represented by 0 in spark.mllib instead of −1, to be consistent with multiclass labeling.\n","def to_example(raw_data_point: DataFrame) -> LabeledPoint:\n","    return LabeledPoint(\\\n","            float(raw_data_point['ARR_DELAY'] < 15),  # on-time? \\\n","            [ \\\n","                raw_data_point['DEP_DELAY'], \\\n","                raw_data_point['TAXI_OUT'], \\\n","                raw_data_point['DISTANCE'], \\\n","            ])\n","\n","examples: DataFrame = traindata.rdd.map(to_example)"]},{"cell_type":"markdown","id":"67f7247c-925e-4df9-913c-4c8dad658266","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"id":"fc5e87f9-2c6b-4d9e-bc1c-a15aa388b527","metadata":{},"outputs":[],"source":["# Creating a model means finding out the weights\n","# w0*x0 + w1*x1 + w2*x2 + b\n","lrmodel: LogisticRegressionModel = LogisticRegressionWithLBFGS.train(examples, intercept=True)"]},{"cell_type":"code","execution_count":null,"id":"0f935dd3-9aca-464a-a069-0fd7e8b79a4c","metadata":{},"outputs":[],"source":["print(lrmodel.weights,lrmodel.intercept)"]},{"cell_type":"code","execution_count":null,"id":"b6a63293-4bb3-4da7-9358-68b019c585ac","metadata":{},"outputs":[],"source":["lrmodel.predict([6.0, 12.0, 594.0])"]},{"cell_type":"code","execution_count":null,"id":"6017b7a3-9321-4edc-80fa-bfca5bcf6ade","metadata":{},"outputs":[],"source":["lrmodel.predict([36.0, 12.0, 594.0])"]},{"cell_type":"code","execution_count":null,"id":"c6f20c78-ab4b-4a29-80fe-1f753854f088","metadata":{},"outputs":[],"source":["lrmodel.clearThreshold()"]},{"cell_type":"code","execution_count":null,"id":"75be74bd-f147-40ec-bcef-452a2704fedf","metadata":{},"outputs":[],"source":["# Predict probability with fixed dep delay and taxi-out\n","dist: np.ndarray = np.arange(10, 2000, 10)\n","prob: list = [lrmodel.predict([20,10,d]) for d in dist]\n","plt.plot(dist, prob)"]},{"cell_type":"code","execution_count":null,"id":"fae81099-65cc-478e-bd8e-db81f94913fe","metadata":{},"outputs":[],"source":["# Predict probability with fixed taxi-out  and distance\n","delay: np.ndarray = np.arange(-20, 60, 1)\n","prob= list = [lrmodel.predict([d, 10, 500]) for d in delay]\n","ax = plt.plot(delay, prob)"]},{"cell_type":"code","execution_count":null,"id":"7e586eac-213c-453b-818d-b71cb902c94e","metadata":{},"outputs":[],"source":["lrmodel.setThreshold(0.7)"]},{"cell_type":"markdown","id":"a3d11261-ba01-427d-adc4-0b4ed35d9b51","metadata":{},"source":["# Predicting by Using a Model"]},{"cell_type":"code","execution_count":null,"id":"f8857866-8f3f-4540-a471-de3e62c9950f","metadata":{},"outputs":[],"source":["# Save model to cloud stroage for future use\n","MODEL_FILE: str = f\"gs://{BUCKET}/flights/sparkmloutput/model\"\n","lrmodel.save(sc, MODEL_FILE)"]},{"cell_type":"code","execution_count":null,"id":"24e6353a-4e8c-4a22-85ac-3fe15eec243e","metadata":{},"outputs":[],"source":["# Predict from saved model in google storage\n","from pyspark.mllib.classification import LogisticRegressionModel\n","lrmodel: LogisticRegressionModel = LogisticRegressionModel.load(sc, MODEL_FILE)\n","lrmodel.setThreshold(0.7)"]},{"cell_type":"code","execution_count":null,"id":"b710a2c3","metadata":{},"outputs":[],"source":["print(lrmodel.predict([36.0, 12.0, 594.0]))"]},{"cell_type":"code","execution_count":null,"id":"f24e1fa4","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}